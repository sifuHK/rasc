{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "668d7963-056f-438c-905d-96d60c6b10ff",
   "metadata": {},
   "source": [
    "Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f2ec9a0-79be-49cc-a283-7e3f1c3e0b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#download  https://github.com/sifuHK/rasc/blob/main/Data/dat.xlsx\n",
    "dat = pd.read_excel('../../Data/dat.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2b9b6a9-31fa-4d55-907e-27519902e89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the default language does not meet the user's needs (following the operating system and rascpy provides the corresponding language pack), \n",
    "# the user can manually switch the language pack (the language pack can be either pre-installed in the rascpy or provided by the user).\n",
    "\n",
    "# from rascpy.Lan_EN import EN\n",
    "# from rascpy import Tree\n",
    "# Tree.lan = EN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5343eb-82ea-42f8-836f-f34a51224867",
   "metadata": {},
   "source": [
    "Splitting Data  \n",
    "1. The `sklearn.model_selection.train_test_split` method is overly simplistic. It only performs stratified sampling based on the y labels and does not sample according to the joint distribution of (X, y). This may lead to significant discrepancies in model evaluation metrics. However, due to the limitations of the sampling algorithm, this issue can only be addressed as overfitting (by sacrificing model validity to enhance model generalization).  \n",
    "2. The `rascpy.Sampling.split_cls` sampling algorithm provided by rascpy is designed for high-precision sampling in binary classification problems. Compared to the stratified sampling offered by `sklearn.model_selection.train_test_split`, it effectively mitigates the inconsistency in the joint distribution of (X, y) across multiple split datasets. This achieves enhanced model generalization without compromising model validity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a75f25c-e9b0-43ac-bd86-ebfb63040a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rascpy.Sampling import split_cls\n",
    "train,valid = split_cls(dat,y='y',test_size=0.3,random_state=0)\n",
    "train_X = train.loc[:,train.columns!='y']\n",
    "valid_X = valid.loc[:,valid.columns!='y']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764c9a80-e9fc-4ca9-ba8f-79894f8d3e47",
   "metadata": {},
   "source": [
    "Train Model  \n",
    "- **cands_num**: Retain the top 5 highest-scoring models.  \n",
    "- **variance_level**: It is generally set to 1. If the variance of the returned models is very small when `variance_level` is set to 1 (i.e., the difference between the metrics on the training set and the validation set is minimal), users can set `variance_level` to 2. This will appropriately sacrifice some of the model's generalization ability to improve its evaluation metrics.  \n",
    "- **cost_time**: In practical use by the author, setting `cost_time` to 3-5 minutes is sufficient to obtain the optimal model for the vast majority of real-world cases. It is not recommended to set it to 8 or higher, as this is highly likely to be a waste of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26f77a3c-e554-4b7e-8da0-364d076aaa9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rascpy.Tree import auto_xgb\n",
    "perf_cands,params_cands,clf_cands,vars_cands = auto_xgb(train_X,train.y,valid_X,valid.y,metric='auc',cost_time=60*5,cands_num=5,variance_level = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfae0969-1324-4b27-9ee1-f5c3bd36fcc2",
   "metadata": {},
   "source": [
    "Return value `perf_cands`: list  \n",
    "The number of elements is the same as `cands_num`. Each element is itself a dictionary, recording the following details for each model:  \n",
    "- Recommendation priority  \n",
    "- `train_xx` (where `xx` represents the metric set by the user)  \n",
    "- `val_xx` (where `xx` represents the metric set by the user)  \n",
    "- `|train - val|` (the absolute difference between the training and validation evaluation metrics)  \n",
    "- Number of input variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d3af438-bf88-4d69-ac32-06a57d835816",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Performance of the model': 1,\n",
       "  'train_auc': np.float64(0.7832),\n",
       "  'val_auc': np.float64(0.7534),\n",
       "  '|train - val|': np.float64(0.02980000000000005),\n",
       "  'Count of variables': np.int64(87)},\n",
       " {'Performance of the model': 2,\n",
       "  'train_auc': np.float64(0.7755),\n",
       "  'val_auc': np.float64(0.7493),\n",
       "  '|train - val|': np.float64(0.0262),\n",
       "  'Count of variables': np.int64(73)},\n",
       " {'Performance of the model': 3,\n",
       "  'train_auc': np.float64(0.7717),\n",
       "  'val_auc': np.float64(0.7472),\n",
       "  '|train - val|': np.float64(0.024500000000000077),\n",
       "  'Count of variables': np.int64(58)},\n",
       " {'Performance of the model': 4,\n",
       "  'train_auc': np.float64(0.7819),\n",
       "  'val_auc': np.float64(0.7516),\n",
       "  '|train - val|': np.float64(0.030299999999999994),\n",
       "  'Count of variables': np.int64(79)},\n",
       " {'Performance of the model': 5,\n",
       "  'train_auc': np.float64(0.7595),\n",
       "  'val_auc': np.float64(0.7365),\n",
       "  '|train - val|': np.float64(0.02299999999999991),\n",
       "  'Count of variables': np.int64(36)}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perf_cands"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81599411-0d5c-4c1d-8d02-8ef0c2798fff",
   "metadata": {},
   "source": [
    "Return value `params_cands`: list  \n",
    "Each element represents the hyperparameters of a model and corresponds directly to each entry in `perf_cands`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "747fe652-570e-4130-9c74-2ad88f11542c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'n_estimators': 877,\n",
       "  'max_depth': 1,\n",
       "  'min_child_weight': np.float64(8.872923967672701),\n",
       "  'learning_rate': np.float64(0.028322515394950374),\n",
       "  'subsample': np.float64(0.9216171973524886),\n",
       "  'colsample_bylevel': np.float64(0.5014526925699818),\n",
       "  'colsample_bytree': np.float64(0.8810992553587585),\n",
       "  'reg_alpha': np.float64(1.5148828490326136),\n",
       "  'reg_lambda': np.float64(0.3692803435996255),\n",
       "  'n_jobs': -1,\n",
       "  'verbosity': 0},\n",
       " {'n_estimators': 825,\n",
       "  'max_depth': 1,\n",
       "  'min_child_weight': np.float64(19.34469455637533),\n",
       "  'learning_rate': np.float64(0.022059412941599865),\n",
       "  'subsample': np.float64(0.8422789854685215),\n",
       "  'colsample_bylevel': np.float64(0.5237206410323396),\n",
       "  'colsample_bytree': np.float64(0.7185684638396863),\n",
       "  'reg_alpha': np.float64(0.21591846567713957),\n",
       "  'reg_lambda': np.float64(0.3949205099231725),\n",
       "  'n_jobs': -1,\n",
       "  'verbosity': 0},\n",
       " {'n_estimators': 201,\n",
       "  'max_depth': 1,\n",
       "  'min_child_weight': np.float64(18.670134585089667),\n",
       "  'learning_rate': np.float64(0.07687465206594996),\n",
       "  'subsample': np.float64(0.7419336068094462),\n",
       "  'colsample_bylevel': np.float64(0.5301734930469847),\n",
       "  'colsample_bytree': np.float64(0.7495933087360644),\n",
       "  'reg_alpha': np.float64(0.9283760318576136),\n",
       "  'reg_lambda': np.float64(0.23947263349788675),\n",
       "  'n_jobs': -1,\n",
       "  'verbosity': 0},\n",
       " {'n_estimators': 226,\n",
       "  'max_depth': 1,\n",
       "  'min_child_weight': np.float64(88.31469529758655),\n",
       "  'learning_rate': np.float64(0.12875880508471685),\n",
       "  'subsample': np.float64(0.9103408679027439),\n",
       "  'colsample_bylevel': np.float64(0.43888481960512254),\n",
       "  'colsample_bytree': np.float64(0.8047201101769103),\n",
       "  'reg_alpha': np.float64(1.5030946690542089),\n",
       "  'reg_lambda': np.float64(0.2401754830169544),\n",
       "  'n_jobs': -1,\n",
       "  'verbosity': 0},\n",
       " {'n_estimators': 195,\n",
       "  'max_depth': 1,\n",
       "  'min_child_weight': np.float64(4.656196565317986),\n",
       "  'learning_rate': np.float64(0.04885504767573405),\n",
       "  'subsample': np.float64(0.9413012273786621),\n",
       "  'colsample_bylevel': np.float64(0.3553050591143711),\n",
       "  'colsample_bytree': np.float64(0.865134771955268),\n",
       "  'reg_alpha': np.float64(7.329569119194987),\n",
       "  'reg_lambda': np.float64(0.25603048399479633),\n",
       "  'n_jobs': -1,\n",
       "  'verbosity': 0}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_cands"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99f60f1-1b7c-45db-9e04-df43d378899c",
   "metadata": {},
   "source": [
    "Return value `clf_cands`: list  \n",
    "Each element is a trained XGBoost model, corresponding one-to-one with the entries in `perf_cands`.  \n",
    "The models are original XGBoost instances, which facilitates deployment and application in production environments without requiring the installation of `rascpy` on the server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "863ac04f-36b9-40b0-8689-56ea0689f3e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "               colsample_bylevel=np.float64(0.5014526925699818),\n",
       "               colsample_bynode=None,\n",
       "               colsample_bytree=np.float64(0.8810992553587585), device=None,\n",
       "               early_stopping_rounds=None, enable_categorical=False,\n",
       "               eval_metric=None, feature_types=None, gamma=None,\n",
       "               grow_policy=None, importance_type=None,\n",
       "               interaction_constraints=None,\n",
       "               learning_rate=np.float64(0.028322515394950374), max_bin=None,\n",
       "               max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "               max_delta_step=None, max_depth=1, max_leaves=None,\n",
       "               min_child_weight=np.float64(8.872923967672701), missing=nan,\n",
       "               monotone_constraints=None, multi_strategy=None, n_estimators=877,\n",
       "               n_jobs=-1, num_parallel_tree=None, random_state=0, ...),\n",
       " XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "               colsample_bylevel=np.float64(0.5237206410323396),\n",
       "               colsample_bynode=None,\n",
       "               colsample_bytree=np.float64(0.7185684638396863), device=None,\n",
       "               early_stopping_rounds=None, enable_categorical=False,\n",
       "               eval_metric=None, feature_types=None, gamma=None,\n",
       "               grow_policy=None, importance_type=None,\n",
       "               interaction_constraints=None,\n",
       "               learning_rate=np.float64(0.022059412941599865), max_bin=None,\n",
       "               max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "               max_delta_step=None, max_depth=1, max_leaves=None,\n",
       "               min_child_weight=np.float64(19.34469455637533), missing=nan,\n",
       "               monotone_constraints=None, multi_strategy=None, n_estimators=825,\n",
       "               n_jobs=-1, num_parallel_tree=None, random_state=0, ...),\n",
       " XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "               colsample_bylevel=np.float64(0.5301734930469847),\n",
       "               colsample_bynode=None,\n",
       "               colsample_bytree=np.float64(0.7495933087360644), device=None,\n",
       "               early_stopping_rounds=None, enable_categorical=False,\n",
       "               eval_metric=None, feature_types=None, gamma=None,\n",
       "               grow_policy=None, importance_type=None,\n",
       "               interaction_constraints=None,\n",
       "               learning_rate=np.float64(0.07687465206594996), max_bin=None,\n",
       "               max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "               max_delta_step=None, max_depth=1, max_leaves=None,\n",
       "               min_child_weight=np.float64(18.670134585089667), missing=nan,\n",
       "               monotone_constraints=None, multi_strategy=None, n_estimators=201,\n",
       "               n_jobs=-1, num_parallel_tree=None, random_state=0, ...),\n",
       " XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "               colsample_bylevel=np.float64(0.43888481960512254),\n",
       "               colsample_bynode=None,\n",
       "               colsample_bytree=np.float64(0.8047201101769103), device=None,\n",
       "               early_stopping_rounds=None, enable_categorical=False,\n",
       "               eval_metric=None, feature_types=None, gamma=None,\n",
       "               grow_policy=None, importance_type=None,\n",
       "               interaction_constraints=None,\n",
       "               learning_rate=np.float64(0.12875880508471685), max_bin=None,\n",
       "               max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "               max_delta_step=None, max_depth=1, max_leaves=None,\n",
       "               min_child_weight=np.float64(88.31469529758655), missing=nan,\n",
       "               monotone_constraints=None, multi_strategy=None, n_estimators=226,\n",
       "               n_jobs=-1, num_parallel_tree=None, random_state=0, ...),\n",
       " XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "               colsample_bylevel=np.float64(0.3553050591143711),\n",
       "               colsample_bynode=None,\n",
       "               colsample_bytree=np.float64(0.865134771955268), device=None,\n",
       "               early_stopping_rounds=None, enable_categorical=False,\n",
       "               eval_metric=None, feature_types=None, gamma=None,\n",
       "               grow_policy=None, importance_type=None,\n",
       "               interaction_constraints=None,\n",
       "               learning_rate=np.float64(0.04885504767573405), max_bin=None,\n",
       "               max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "               max_delta_step=None, max_depth=1, max_leaves=None,\n",
       "               min_child_weight=np.float64(4.656196565317986), missing=nan,\n",
       "               monotone_constraints=None, multi_strategy=None, n_estimators=195,\n",
       "               n_jobs=-1, num_parallel_tree=None, random_state=0, ...)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_cands"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab9a925-5d13-4fba-af82-d00569a979b3",
   "metadata": {},
   "source": [
    "Return value `vars_cands`: list  \n",
    "Each element contains the actual input variables used by the model, corresponding one-to-one with the entries in `perf_cands`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8284c34a-bc4e-416c-aa4b-edbb1f8edaa6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['x3', 'x4', 'x5', 'x6', 'x9', 'x11', 'x12', 'x19', 'x20', 'x26',\n",
       "        'x29', 'x34', 'x35', 'x37', 'x38', 'x43', 'x47', 'x56', 'x57',\n",
       "        'x61', 'x62', 'x63', 'x67', 'x84', 'x89', 'x90', 'x95', 'x96',\n",
       "        'x100', 'x101', 'x102', 'x103', 'x104', 'x105', 'x109', 'x110',\n",
       "        'x111', 'x116', 'x117', 'x119', 'x120', 'x121', 'x122', 'x124',\n",
       "        'x126', 'x129', 'x130', 'x131', 'x134', 'x138', 'x143', 'x144',\n",
       "        'x147', 'x148', 'x150', 'x151', 'x152', 'x155', 'x157', 'x163',\n",
       "        'x167', 'x168', 'x169', 'x170', 'x174', 'x175', 'x176', 'x180',\n",
       "        'x188', 'x189', 'x190', 'x191', 'x192', 'x193', 'x194', 'x196',\n",
       "        'x197', 'x201', 'x207', 'x208', 'x209', 'x210', 'x211', 'x214',\n",
       "        'x215', 'x216', 'x217'], dtype='<U4'),\n",
       " array(['x3', 'x4', 'x5', 'x9', 'x15', 'x19', 'x20', 'x34', 'x35', 'x37',\n",
       "        'x38', 'x43', 'x47', 'x56', 'x57', 'x61', 'x62', 'x63', 'x67',\n",
       "        'x84', 'x89', 'x90', 'x95', 'x96', 'x100', 'x101', 'x102', 'x103',\n",
       "        'x104', 'x105', 'x109', 'x110', 'x111', 'x116', 'x119', 'x120',\n",
       "        'x121', 'x129', 'x130', 'x131', 'x134', 'x138', 'x143', 'x144',\n",
       "        'x150', 'x151', 'x155', 'x157', 'x163', 'x167', 'x168', 'x169',\n",
       "        'x170', 'x174', 'x176', 'x180', 'x188', 'x189', 'x190', 'x191',\n",
       "        'x192', 'x196', 'x197', 'x201', 'x207', 'x208', 'x209', 'x210',\n",
       "        'x214', 'x215', 'x216', 'x217', 'x219'], dtype='<U4'),\n",
       " array(['x1', 'x3', 'x4', 'x5', 'x9', 'x19', 'x20', 'x34', 'x35', 'x37',\n",
       "        'x38', 'x56', 'x57', 'x61', 'x62', 'x63', 'x84', 'x89', 'x90',\n",
       "        'x95', 'x96', 'x100', 'x103', 'x104', 'x105', 'x109', 'x116',\n",
       "        'x119', 'x121', 'x130', 'x131', 'x132', 'x134', 'x136', 'x139',\n",
       "        'x144', 'x151', 'x155', 'x157', 'x158', 'x163', 'x167', 'x168',\n",
       "        'x169', 'x170', 'x174', 'x176', 'x180', 'x191', 'x194', 'x197',\n",
       "        'x201', 'x207', 'x208', 'x209', 'x210', 'x215', 'x217'],\n",
       "       dtype='<U4'),\n",
       " array(['x1', 'x3', 'x4', 'x5', 'x8', 'x9', 'x11', 'x19', 'x20', 'x26',\n",
       "        'x28', 'x29', 'x34', 'x35', 'x37', 'x38', 'x43', 'x47', 'x52',\n",
       "        'x56', 'x57', 'x61', 'x62', 'x63', 'x76', 'x84', 'x86', 'x89',\n",
       "        'x90', 'x95', 'x96', 'x100', 'x101', 'x102', 'x103', 'x105',\n",
       "        'x109', 'x111', 'x116', 'x117', 'x119', 'x120', 'x121', 'x122',\n",
       "        'x126', 'x130', 'x131', 'x134', 'x137', 'x144', 'x147', 'x148',\n",
       "        'x150', 'x151', 'x155', 'x157', 'x163', 'x167', 'x168', 'x169',\n",
       "        'x170', 'x176', 'x180', 'x188', 'x190', 'x191', 'x192', 'x193',\n",
       "        'x194', 'x196', 'x197', 'x207', 'x208', 'x209', 'x210', 'x211',\n",
       "        'x215', 'x216', 'x217'], dtype='<U4'),\n",
       " array(['x9', 'x19', 'x20', 'x35', 'x37', 'x56', 'x57', 'x61', 'x63',\n",
       "        'x67', 'x84', 'x89', 'x90', 'x96', 'x103', 'x105', 'x109', 'x119',\n",
       "        'x121', 'x129', 'x130', 'x131', 'x134', 'x151', 'x157', 'x167',\n",
       "        'x168', 'x169', 'x170', 'x176', 'x180', 'x191', 'x197', 'x207',\n",
       "        'x209', 'x217'], dtype='<U4')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars_cands"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddeaa461-b444-41a4-9285-874388ecc2a6",
   "metadata": {},
   "source": [
    "Users can select the model they need by index for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2561687-be02-4e11-b5ed-e3c0ec6b8c7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9709641  0.02903594]\n",
      " [0.9679828  0.03201716]\n",
      " [0.98568344 0.01431655]\n",
      " ...\n",
      " [0.56139714 0.43860286]\n",
      " [0.7213056  0.2786944 ]\n",
      " [0.67495286 0.3250471 ]]\n",
      "------------------------------\n",
      "2785     0.0290\n",
      "3506     0.0320\n",
      "27512    0.0143\n",
      "29244    0.0118\n",
      "28684    0.0209\n",
      "          ...  \n",
      "38852    0.4711\n",
      "26433    0.2351\n",
      "2124     0.4386\n",
      "25394    0.2787\n",
      "27479    0.3250\n",
      "Length: 11779, dtype: float64\n",
      "------------------------------\n",
      "2785     0.0290\n",
      "3506     0.0320\n",
      "27512    0.0143\n",
      "29244    0.0118\n",
      "28684    0.0209\n",
      "          ...  \n",
      "38852    0.4711\n",
      "26433    0.2351\n",
      "2124     0.4386\n",
      "25394    0.2787\n",
      "27479    0.3250\n",
      "Length: 11779, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# clf_cands[0]: Select the first model recommended by the automatic optimization algorithm. Similarly, users can choose any model from the candidate models for use.\n",
    "xgb_model = clf_cands[0]\n",
    "\n",
    "# XGBoost's native predict_proba requires passing all variables used during training to the XGBoost model.\n",
    "hat = xgb_model.predict_proba(valid_X)\n",
    "\n",
    "# The native predict_proba returns a two-dimensional numpy.ndarray containing probabilities for class 0 and class 1.\n",
    "print(hat)\n",
    "print('-' * 30)\n",
    "\n",
    "# Using rascpy's built-in predict_proba, the model automatically ignores variables not required by the model during prediction, even if these variables were used during training.\n",
    "from rascpy.Tool import predict_proba\n",
    "\n",
    "# Only the variables actually used by the model need to be passed. This is more friendly for online model deployment, but the server needs to have rascpy installed.\n",
    "cols_in_model = vars_cands[0]\n",
    "hat = predict_proba(xgb_model, valid_X[cols_in_model], decimals=4)\n",
    "\n",
    "# Returns a pandas.Series containing only the probability of class 1, while preserving the index column of the input data.\n",
    "print(hat)\n",
    "print('-' * 30)\n",
    "\n",
    "# Of course, redundant variables can also be passed to rascpy.predict_proba, which will automatically filter them out.\n",
    "hat = predict_proba(xgb_model, valid)\n",
    "\n",
    "# The returned result is the same as when passing valid_X[cols_in_model].\n",
    "print(hat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
